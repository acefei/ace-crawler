网站爬虫的实践积累
====

### Usage
详情见prototypes/executors目录内各脚本的 __doc__

### Feature
1. 集成scrapy-redis
2. 改造dupefilter，使用bloomfilter
3. 通用网页正文抽取
4. 集成[爬虫代理IP池](https://github.com/acefei/proxy_pool)
5. 搜狗搜索爬虫，url解密

### Inspiration
[反击爬虫，前端工程师的脑洞可以有多大？](http://web.jobbole.com/92736/)

